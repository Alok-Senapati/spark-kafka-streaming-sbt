processor_class = "org.example.streaming.BatchProcessor"

dev {
  kafka {
    bootstrap_server = "localhost:9092"
    topic = "kafka-python-01"
    checkpoint_location = "hdfs://localhost:9000/spark/spark-streaming-checkpoint/batch_hive_loader"
    group_id = "kafka-batch-hive-group-01"
    micro_batch_interval = "300 seconds"
  }

  hive {
    table_name = "ecomm.orders_raw"
    partition_columns = "processingTimestamp"
  }

  spark {
    app.name = "KafkaStreamConsoleWriter"
    master = "local"
    sql.catalogImplementation = "hive"
    streaming.stopGracefullyOnShutdown = "true"
  }
}
